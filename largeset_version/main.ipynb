{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "file_path = 'SpotifyFeatures.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vizualiing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visulize \"duplicate songs\"(same trackid = same song)\n",
    "data['track_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display how many songs are \"duplicated\"(same trackid = same song) distrobution\n",
    "data['track_id'].value_counts().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample to Understand why there are duplicated songs\n",
    "data[data['track_id'] == '6AIte2Iej1QKlaofpjCzW1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visulize the distribution of songs into all genres\n",
    "data['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many songs are above 50 in popularity\n",
    "hits = data[data['popularity'] > 50].shape[0]\n",
    "miss = data[data['popularity'] < 50].shape[0]\n",
    "\n",
    "# visulize the distribution of popularity\n",
    "sns.histplot(data['popularity'], kde=True)\n",
    "plt.show()\n",
    "\n",
    "hits_ratio = hits/(hits+miss)*100\n",
    "print(f\"{hits_ratio:.3f}% of the songs are above 50 in popularity\")\n",
    "print(f\"with an average popularity of {data['popularity'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "- data has songs that are to long we want 8.3 minutes to be max and 1 minute to be min because we want to measure normal songs\n",
    "- some attributes need to be transformed to numerical scale\n",
    "- A capella is to small to be considered\n",
    "- Children's Music and Children’s Music should be the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prepping steps\n",
    "- remove song that are to long in duration songs longer than 500000 ms (500 seconds = 8.3 minutes)\n",
    "- remove songs that are to short in duration songs shorter than 60000 ms (60 seconds = 1 minute)\n",
    "- Remove A Capella songs due to being to small\n",
    "- Combine union child genres into one genre Children's Music\n",
    "- Split songs into it's genres\n",
    "- Convert songs to Miss or Hit based on popularity\n",
    "\n",
    "### Create new attribute\n",
    "- Genre count for each song with multilabeld genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop songs that are to long\n",
    "data = data[data['duration_ms'] < 500000]\n",
    "# Drop songs that are to short \n",
    "data = data[data['duration_ms'] > 60000]\n",
    "\n",
    "# drop gernre a capella\n",
    "data = data[data['genre'] != 'A Capella']\n",
    "\n",
    "# Combine union child genres\n",
    "data['genre'] = data['genre'].replace('Children’s Music', 'Children\\'s Music')\n",
    "\n",
    "# Create a new column for genre count\n",
    "data['genre_count'] = data.groupby('track_id')['genre'].transform('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "- Pitch preprocessing\n",
    "- Time signature preprocessing\n",
    "- Mode preprocessing (minor/major)\n",
    "- Create datasets for each genre\n",
    "- Flop or Bop labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert pitch to number\n",
    "def pitch_to_number(pitch):\n",
    "    pitch_map = {\n",
    "        'C': 0,\n",
    "        'C#': 1, 'Db': 1,\n",
    "        'D': 2,\n",
    "        'D#': 3, 'Eb': 3,\n",
    "        'E': 4, 'Fb': 4,\n",
    "        'E#': 5, 'F': 5,\n",
    "        'F#': 6, 'Gb': 6,\n",
    "        'G': 7,\n",
    "        'G#': 8, 'Ab': 8,\n",
    "        'A': 9,\n",
    "        'A#': 10, 'Bb': 10,\n",
    "        'B': 11, 'Cb': 11\n",
    "    }\n",
    "    return pitch_map.get(pitch, None)\n",
    "\n",
    "# Replace the pitch column with its numeric representation\n",
    "# Assuming the column name in your DataFrame that contains pitch values is 'pitch_column'\n",
    "data['key'] = data['key'].apply(pitch_to_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['time_signature'] = (data['time_signature'].apply(lambda x: x.split('/')[0])).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the mode column to 1 for major and 0 for minor\n",
    "data['mode'] = data['mode'].replace(\"Minor\", 0)\n",
    "data['mode'] = data['mode'].replace(\"Major\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by genre and calculate mean popularity\n",
    "grouped = data.groupby('genre')\n",
    "mean_popularity = grouped['popularity'].mean()\n",
    "mean_popularity = mean_popularity.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to label rows as 'bop' or 'flop'\n",
    "def label_popularity(row, mean_popularity):\n",
    "    if row['popularity'] >= mean_popularity[row['genre']]:\n",
    "        return 'bop'\n",
    "    else:\n",
    "        return 'flop'\n",
    "\n",
    "# Apply the function to each row\n",
    "data['popularity_label'] = data.apply(lambda row: label_popularity(row, mean_popularity), axis=1)\n",
    "\n",
    "# Splitting the data into bop and flop, ensuring each genre is split 50/50\n",
    "# This step might require adjusting the labels for genres with an odd number of entries\n",
    "for genre in data['genre'].unique():\n",
    "    genre_data = data[data['genre'] == genre]\n",
    "    n = len(genre_data) // 2\n",
    "    popular_indices = genre_data.nlargest(n, 'popularity').index\n",
    "    nonpopular_indices = genre_data.nsmallest(n, 'popularity').index\n",
    "    data.loc[popular_indices, 'popularity_label'] = 'bop'\n",
    "    data.loc[nonpopular_indices, 'popularity_label'] = 'flop'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization so far\n",
    "- Visualize the distribution of the target variable in terms of genres\n",
    "- Visualize the distribution of bop and flop songs in terms of genres songs from spotify with a popularity over 50 and under 50\n",
    "- Visualize the distribution of the new 50/50 split to balance the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the popularity of each genre and color children's music\n",
    "mean_popularity.plot(kind='bar', figsize=(15, 10))\n",
    "colors = ['red' if genre == 'Children\\'s Music' else 'skyblue' for genre in mean_popularity.index]\n",
    "plt.bar(mean_popularity.index, mean_popularity, color=colors)\n",
    "plt.title('Mean Popularity of Each Genre')\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Mean Popularity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['popularity_over_50'] = data['popularity'] >= 50\n",
    "\n",
    "popularity_over_50_df = data.groupby(['genre', 'popularity_over_50']).size().unstack(fill_value=0)\n",
    "popularity_over_50_df['total'] = popularity_over_50_df.sum(axis=1)\n",
    "popularity_over_50_df_sorted = popularity_over_50_df.sort_values(by='total', ascending=False)\n",
    "popularity_over_50_df_sorted = popularity_over_50_df_sorted.drop(columns='total')\n",
    "\n",
    "# Plotting\n",
    "popularity_over_50_df_sorted.plot(kind='bar', stacked=True, figsize=(20, 10))\n",
    "plt.title('Popularity Over 50 by Genre')\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_dict_over50 = {}\n",
    "for genre in data['genre'].unique():\n",
    "    genre_data = data[data['genre'] == genre]\n",
    "    genre_data = genre_data.dropna()\n",
    "    X = genre_data[['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence']]\n",
    "    y = genre_data['popularity_over_50']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    accuracy_dict_over50[genre] = accuracy\n",
    "    print(f'Accuracy for {genre}: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_dict_over50 = dict(sorted(accuracy_dict_over50.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "accuracy_df = pd.DataFrame(list(accuracy_dict_over50.items()), columns=['Genre', 'Accuracy'])\n",
    "\n",
    "accuracy_df.plot(kind='bar', x='Genre', y='Accuracy', figsize=(20, 10), legend=True)\n",
    "plt.title('Model Accuracy by Genre')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Genre')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "popularity_label_df = data.groupby(['genre', 'popularity_label']).size().unstack(fill_value=0)\n",
    "\n",
    "\n",
    "popularity_label_df['total'] = popularity_label_df.sum(axis=1)\n",
    "\n",
    "\n",
    "popularity_label_df_sorted = popularity_label_df.sort_values(by='total', ascending=False)\n",
    "popularity_label_df_sorted = popularity_label_df_sorted.drop(columns='total')\n",
    "\n",
    "popularity_label_df_sorted.plot(kind='bar', stacked=True, figsize=(20, 10))\n",
    "plt.title('Popularity Label by Genre')\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_dict_50percent = {}\n",
    "for genre in data['genre'].unique():\n",
    "    genre_data = data[data['genre'] == genre]\n",
    "    genre_data = genre_data.dropna()\n",
    "    X = genre_data[['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence']]\n",
    "    y = genre_data['popularity_label']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    accuracy_dict_50percent[genre] = accuracy\n",
    "    print(f'Accuracy for {genre}: {accuracy}')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_dict_50percent = dict(sorted(accuracy_dict_50percent.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "accuracy_df = pd.DataFrame(list(accuracy_dict_50percent.items()), columns=['Genre', 'Accuracy'])\n",
    "\n",
    "# Plotting\n",
    "accuracy_df.plot(kind='bar', x='Genre', y='Accuracy', figsize=(20, 10), legend=True)\n",
    "plt.title('Model Accuracy by Genre')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Genre')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments on genre selection to further analyze\n",
    "- By splitting the genres into it's own column we can now analyze the data in terms of genres this results in us having 25 datasets to analyze. To make the analysis easier to understand we will only analyze the biggest dataset children's music. \n",
    "\n",
    "### Next steps\n",
    "- quick overview\n",
    "  - check for duplicates\n",
    "  - check avg popularity (to understand target variable)\n",
    "  - find weird values\n",
    "  - Analyze artist distribution (to understand if the artst with the most songs can make the dataset biased) # side note: Each artist has a different style so this could be a good thing\n",
    "- Analyze "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "childrens_music = data[data['genre'] == 'Children\\'s Music']\n",
    "# plot the distribution of popularity for children's music\n",
    "sns.histplot(childrens_music['popularity'])\n",
    "plt.title('Popularity Distribution for Children\\'s Music')\n",
    "plt.xlabel('Popularity')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "print(childrens_music['popularity'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for songs with same track_id to find duplicates\n",
    "print(childrens_music[childrens_music['track_id'].duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find songs with bad values - like the sample below\n",
    "childrens_music[childrens_music['track_id'] == '7ARLbcqLgOrBI2JfzfKtHD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the $ in the track_name and artist_name columns with s\n",
    "childrens_music.loc[:, 'track_name'] = childrens_music['track_name'].str.replace('$', 's')\n",
    "childrens_music.loc[:, 'artist_name'] = childrens_music['artist_name'].str.replace('$', 's')\n",
    "\n",
    "childrens_music[childrens_music['track_id'] == '7ARLbcqLgOrBI2JfzfKtHD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_songs = len(childrens_music)\n",
    " \n",
    "# Calculate the average popularity for each artist\n",
    "avg_popularity_by_artist = childrens_music.groupby('artist_name')['popularity'].mean()\n",
    "\n",
    "# Find the top 20 artists by the number of songs\n",
    "top_20_artists = childrens_music['artist_name'].value_counts().head(20)\n",
    "top_20_artists_df = top_20_artists.reset_index()\n",
    "top_20_artists_df.columns = ['artist_name', 'Song Count']\n",
    "\n",
    "# Merge the average popularity data with the top 20 artists DataFrame\n",
    "top_20_artists_with_avg_popularity = pd.merge(top_20_artists_df, avg_popularity_by_artist, on='artist_name')\n",
    "\n",
    "# Calculate the share of total songs for each of the top 20 artists and add it to the DataFrame\n",
    "top_20_artists_with_avg_popularity['% of songs'] = (top_20_artists_with_avg_popularity['Song Count'] / total_songs) * 100\n",
    "\n",
    "#'Share of Total Songs (%)' round 2 decimals\n",
    "top_20_artists_with_avg_popularity['popularity'] = top_20_artists_with_avg_popularity['popularity'].round(2)\n",
    "top_20_artists_with_avg_popularity['% of songs'] = top_20_artists_with_avg_popularity['% of songs'].round(2)\n",
    "\n",
    "print(top_20_artists_with_avg_popularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the columns to plot with audio features, duration and genre count\n",
    "columns = ['acousticness', 'danceability', 'duration_ms', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'genre_count']\n",
    "\n",
    "# Create a figure and axis to plot on\n",
    "fig, ax = plt.subplots(5, 2, figsize=(20, 20))\n",
    "\n",
    "# Flatten the axis to make it easier to iterate over\n",
    "ax = ax.flatten()\n",
    "\n",
    "# Iterate over the columns and plot each one\n",
    "for i, col in enumerate(columns):\n",
    "    sns.histplot(childrens_music[col], kde=True, ax=ax[i])\n",
    "    ax[i].set_title(f'{col} Distribution')\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dive deeper into instrumentalness\n",
    "instrumentalness = childrens_music['instrumentalness']\n",
    "instrumentalness.describe()\n",
    "\n",
    "# show the most common values for instrumentalness and how many songs are above 0\n",
    "instrumentalness.value_counts().head(10), childrens_music.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test a model to see \n",
    "- feature importance\n",
    "- current preformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a test to see what feature is the most important\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create a new DataFrame with only the audio features and the popularity label\n",
    "X = childrens_music[['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo']]\n",
    "y = childrens_music['popularity_label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model_0 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model_0.fit(X_train, y_train)\n",
    "y_pred = model_0.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(model_0.feature_importances_, index=X_train.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
    "print(\"feature importances\")\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Conclusion on Children's Music dataset\n",
    "- The 2 biggest artists are contributing to 10% of the dataset which is not to much to make the dataset biased \n",
    "- The dataset need some some scaling and normalization to be able to use it in a model\n",
    "- the target variable is now flop or bop and popularity is not needed anymore\n",
    "- The most import features can be viewed above.\n",
    "- The dataset is now free from weird values and duplicates\n",
    "\n",
    "### Next steps\n",
    "- preform log transformation on the dataset to make it a tiny bit more normal distributed\n",
    "- split the dataset into a train and test set before scaling to prevent data leakage\n",
    "- scale the dataset before preforming PCA\n",
    "- preform PCA to reduce the dimensionality of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preform logtransofrmation on livness, speechiness\n",
    "childrens_music['liveness'] = np.log1p(childrens_music['liveness'])\n",
    "childrens_music['speechiness'] = np.log1p(childrens_music['speechiness'])\n",
    "\n",
    "# Create a figure and axis to plot on\n",
    "fig, ax = plt.subplots(5, 2, figsize=(20, 20))\n",
    "\n",
    "# Flatten the axis to make it easier to iterate over\n",
    "ax = ax.flatten()\n",
    "\n",
    "# Iterate over the columns and plot each one\n",
    "for i, col in enumerate(columns):\n",
    "    sns.histplot(childrens_music[col], kde=True, ax=ax[i])\n",
    "    ax[i].set_title(f'{col} Distribution')\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# get data to csv\n",
    "childrens_music.to_csv('childrens_music.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What data do we want and what order do we want it\n",
    "X = childrens_music[['track_name', 'artist_name', 'track_id', 'genre_count','mode', 'time_signature','acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'duration_ms', 'valence']]\n",
    "y = childrens_music['popularity_label']\n",
    "\n",
    "# Split the data into a training and testing set for final model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_features = ['genre_count', 'mode', 'time_signature','acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence']\n",
    "\n",
    "model_2 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "model_2.fit(X_train[predict_features], y_train)\n",
    "\n",
    "y_pred = model_2.predict(X_test[predict_features])\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "feature_importances = pd.DataFrame(model_2.feature_importances_, index=predict_features, columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling selection\n",
    "Standard scaler: This technique transforms the features so they have the properties of a standard normal distribution with a mean of 0 and a standard deviation of 1. It's useful when your data follows a Gaussian distribution and when using algorithms sensitive to variance in the data, such as Support Vector Machines (SVMs) and Principal Component Analysis (PCA). From this we will exclude genre count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Selecting the numerical features for standardization\n",
    "numerical_features = ['acousticness', 'danceability', 'duration_ms', 'energy', \n",
    "                      'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence']\n",
    "\n",
    "# Standardizing the numerical features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])\n",
    "\n",
    "# Transform the testing data\n",
    "X_test[numerical_features] = scaler.transform(X_test[numerical_features])\n",
    "\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_features = ['genre_count', 'mode', 'time_signature','acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence']\n",
    "\n",
    "model_2 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "model_2.fit(X_train[predict_features], y_train)\n",
    "\n",
    "y_pred = model_2.predict(X_test[predict_features])\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train[features] is your scaled dataset for training\n",
    "features = ['acousticness', 'danceability', 'duration_ms', 'energy', \n",
    "            'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence', 'genre_count', 'mode', 'time_signature']\n",
    "\n",
    "# Correlation analysis\n",
    "corr_matrix = np.corrcoef(X_train[features].T)\n",
    "sns.heatmap(corr_matrix, annot=True)\n",
    "plt.show()\n",
    "\n",
    "high_correlation_threshold = 0.41 # \n",
    "\n",
    "# Calculate the number of variables with at least one high correlation\n",
    "# We subtract the count by the length of the matrix to ignore the diagonal (self-correlation)\n",
    "high_correlations = np.sum((np.abs(corr_matrix) > high_correlation_threshold) & (corr_matrix != 1)) / 2\n",
    "\n",
    "\n",
    "# Decide whether PCA is recommended\n",
    "# This threshold can be adjusted based on the size of the matrix or domain knowledge\n",
    "pca_recommended = high_correlations > len(corr_matrix) * 0.5\n",
    "\n",
    "print(f\"PCA is {'recommended' if pca_recommended else 'not recommended'} based on the correlation matrix. There are {int(high_correlations)} pairs of highly correlated variables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We decided to use PCA\n",
    "because we want to see the impact of the features on the target variable and we want to see if we can reduce the dimensionality of the dataset. But from the analysis we can see that the dataset is not to big so we might not need to use PCA and the correlation between the features are not to high so we might not need to use PCA. But we will still use it to see if we can reduce the dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(X_train[features])\n",
    "\n",
    "# Calculating the cumulative explained variance ratio\n",
    "cumulative_explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "limit = 0.85\n",
    "\n",
    "# Plotting the cumulative explained variance to visualize the optimal number of components\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance, marker='o', linestyle='--')\n",
    "plt.title('Cumulative Explained Variance by PCA Components')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.axhline(y=limit, color='r', linestyle='--', label='85% Explained Variance')\n",
    "plt.axvline(x=np.where(cumulative_explained_variance >= limit)[0][0] + 1, color='r', linestyle='--')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# To find the exact number of components explaining 85% of the variance\n",
    "optimal_n_components = np.where(cumulative_explained_variance >= limit)[0][0] + 1\n",
    "print(f\"Optimal number of components to retain 85% of the variance: {optimal_n_components}\")\n",
    "\n",
    "# Now, fitting PCA again with the optimal number of components found\n",
    "pca_optimal = PCA(n_components=optimal_n_components)\n",
    "X_train_pca_optimal = pca_optimal.fit_transform(X_train[features])\n",
    "X_test_pca_optimal = pca_optimal.transform(X_test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, creating a DataFrame for the PCA-transformed training data for easier analysis\n",
    "pca_columns = [f'PC{i+1}' for i in range(optimal_n_components)]\n",
    "pca_train_df = pd.DataFrame(X_train_pca_optimal, columns=pca_columns)\n",
    "\n",
    "# Similarly, creating a DataFrame for the PCA-transformed testing data\n",
    "pca_test_df = pd.DataFrame(X_test_pca_optimal, columns=pca_columns)\n",
    "\n",
    "# Display the first few rows of the PCA-transformed training DataFrame\n",
    "print(pca_train_df.head())\n",
    "\n",
    "# Additionally, to examine the variance explained by the chosen components\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_variance = explained_variance_ratio.cumsum()\n",
    "\n",
    "print(\"Explained variance ratio by component:\", explained_variance_ratio)\n",
    "print(\"Cumulative variance explained:\", cumulative_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with PCA\n",
    "model_pca = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "model_pca.fit(X_train_pca_optimal, y_train)\n",
    "\n",
    "y_pred_pca = model_pca.predict(X_test_pca_optimal)\n",
    "\n",
    "print(classification_report(y_test, y_pred_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification model selection\n",
    "- Random Forest classifier\n",
    "- Support Vector Machine\n",
    "- XGBoost\n",
    "- Logistic Regression \n",
    "- Decision Tree Classifier\n",
    "- K-Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of the best model\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, roc_auc_score \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# The datasets with PCA components\n",
    "X_train_pca_optimal, X_test_pca_optimal\n",
    "\n",
    "# The datasets without PCA components\n",
    "X_train_normal = X_train[features]\n",
    "X_test_normal = X_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert flop or bop to 0 or 1\n",
    "y_train = y_train.replace({'flop': 0, 'bop': 1})\n",
    "y_test = y_test.replace({'flop': 0, 'bop': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC_Model = RandomForestClassifier()\n",
    "RFC_Model.fit(X_train_normal, y_train)\n",
    "RFC_Predict = RFC_Model.predict(X_test_normal)\n",
    "RFC_Accuracy = accuracy_score(y_test, RFC_Predict)\n",
    "print(\"Accuracy: \" + str(RFC_Accuracy))\n",
    "RFC_AUC = roc_auc_score(y_test, RFC_Predict)\n",
    "print(\"AUC: \" + str(RFC_AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_Model = SVC()\n",
    "SVC_Model.fit(X_train_normal, y_train)\n",
    "SVC_Predict = SVC_Model.predict(X_test_normal)\n",
    "SVC_Accuracy = accuracy_score(y_test, SVC_Predict)\n",
    "print(\"Accuracy: \" + str(SVC_Accuracy))\n",
    "SVC_AUC = roc_auc_score(y_test, SVC_Predict)\n",
    "print(\"AUC: \" + str(SVC_AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With PCA\n",
    "SVC_Model = SVC()\n",
    "SVC_Model.fit(X_train_pca_optimal, y_train)\n",
    "SVC_Predict = SVC_Model.predict(X_test_pca_optimal)\n",
    "SVC_Accuracy = accuracy_score(y_test, SVC_Predict)\n",
    "print(\"Accuracy: \" + str(SVC_Accuracy))\n",
    "SVC_AUC = roc_auc_score(y_test, SVC_Predict)\n",
    "print(\"AUC: \" + str(SVC_AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_Model = XGBClassifier()\n",
    "XGB_Model.fit(X_train_normal, y_train)\n",
    "XGB_Predict = XGB_Model.predict(X_test_normal)\n",
    "XGB_Accuracy = accuracy_score(y_test, XGB_Predict)\n",
    "print(\"Accuracy: \" + str(XGB_Accuracy))\n",
    "XGB_AUC = roc_auc_score(y_test, XGB_Predict)\n",
    "print(\"AUC: \" + str(XGB_AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_Model = LogisticRegression()\n",
    "LR_Model.fit(X_train_normal, y_train)\n",
    "LR_Predict = LR_Model.predict(X_test_normal)\n",
    "LR_Accuracy = accuracy_score(y_test, LR_Predict)\n",
    "print(\"Accuracy: \" + str(LR_Accuracy))\n",
    "LR_AUC = roc_auc_score(y_test, LR_Predict) \n",
    "print(\"AUC: \" + str(LR_AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_Model = DecisionTreeClassifier()\n",
    "DT_Model.fit(X_train_normal, y_train)\n",
    "DT_Predict = DT_Model.predict(X_test_normal)\n",
    "DT_Accuracy = accuracy_score(y_test, DT_Predict)\n",
    "print(\"Accuracy: \" + str(DT_Accuracy))\n",
    "DT_AUC = roc_auc_score(y_test, DT_Predict)\n",
    "print(\"AUC: \" + str(DT_AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whit PCA\n",
    "DT_Model = DecisionTreeClassifier()\n",
    "DT_Model.fit(X_train_pca_optimal, y_train)\n",
    "DT_Predict = DT_Model.predict(X_test_pca_optimal)\n",
    "DT_Accuracy = accuracy_score(y_test, DT_Predict)\n",
    "print(\"Accuracy: \" + str(DT_Accuracy))\n",
    "DT_AUC = roc_auc_score(y_test, DT_Predict)\n",
    "print(\"AUC: \" + str(DT_AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNears Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_Model = KNeighborsClassifier()\n",
    "KNN_Model.fit(X_train_normal, y_train)\n",
    "KNN_Predict = KNN_Model.predict(X_test_normal)\n",
    "KNN_Accuracy = accuracy_score(y_test, KNN_Predict)\n",
    "print(\"Accuracy: \" + str(KNN_Accuracy))\n",
    "KNN_AUC = roc_auc_score(y_test, KNN_Predict)\n",
    "print(\"AUC: \" + str(KNN_AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With PCA\n",
    "KNN_Model = KNeighborsClassifier()\n",
    "KNN_Model.fit(X_train_pca_optimal, y_train)\n",
    "KNN_Predict = KNN_Model.predict(X_test_pca_optimal)\n",
    "KNN_Accuracy = accuracy_score(y_test, KNN_Predict)\n",
    "print(\"Accuracy: \" + str(KNN_Accuracy))\n",
    "KNN_AUC = roc_auc_score(y_test, KNN_Predict)\n",
    "print(\"AUC: \" + str(KNN_AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ascending in accuracy and then an plot for AUC\n",
    "models = ['RFC', 'SVC', 'XGB', 'LR', 'DT', 'KNN']\n",
    "accuracy = [RFC_Accuracy, SVC_Accuracy, XGB_Accuracy, LR_Accuracy, DT_Accuracy, KNN_Accuracy]\n",
    "auc = [RFC_AUC, SVC_AUC, XGB_AUC, LR_AUC, DT_AUC, KNN_AUC]\n",
    "\n",
    "accuracy_df = pd.DataFrame({'Model': models, 'Accuracy': accuracy})\n",
    "auc_df = pd.DataFrame({'Model': models, 'AUC': auc})\n",
    "\n",
    "accuracy_df = accuracy_df.sort_values(by='Accuracy', ascending=True)\n",
    "auc_df = auc_df.sort_values(by='AUC', ascending=True)\n",
    "\n",
    "best_model_accuracy = accuracy_df.iloc[-1]['Model']\n",
    "best_model_AUC = auc_df.iloc[-1]['Model']\n",
    "\n",
    "print(f\"The best model based on accuracy is {best_model_accuracy} with an accuracy of {accuracy_df.iloc[-1]['Accuracy']:.3f}\")\n",
    "print(f\"The best model based on AUC is {best_model_AUC} with an AUC of {auc_df.iloc[-1]['AUC']:.3f}\")\n",
    "\n",
    "color_accuracy = ['skyblue' if model != best_model_accuracy else 'red' for model in accuracy_df['Model']]\n",
    "color_auc = ['skyblue' if model != best_model_AUC else 'red' for model in auc_df['Model']]\n",
    "\n",
    "# plot in subplots color the best model\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 3))\n",
    "\n",
    "accuracy_df.plot(kind='bar', x='Model', y='Accuracy', ax=ax[0], legend=False, color=color_accuracy)\n",
    "ax[0].set_title('Model Accuracy Score')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "\n",
    "auc_df.plot(kind='bar', x='Model', y='AUC', ax=ax[1], legend=False, color=color_auc)\n",
    "ax[1].set_title('Model AUC Score')\n",
    "ax[1].set_ylabel('AUC')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# list format for the best model\n",
    "accuracy_df.sort_values(by='Accuracy', ascending=False), auc_df.sort_values(by='AUC', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
